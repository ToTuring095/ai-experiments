# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D_9jklVNvcG5pJxlDaz7MZjSuLQwKOkY
"""

# Import delle librerie
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import xgboost as xgb

# Lettura dataset
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")

# Separazione della variabile target dal train
y = train['SalePrice']
X = train.drop(['SalePrice'], axis=1)

# Concatenazione train e test per il preprocessing unificato
full_data = pd.concat([X, test], axis=0, ignore_index=True)

# Identificazione delle colonne categoriche
cat_cols = [col for col in full_data.columns if full_data[col].dtype == 'object']

# Preprocessing delle colonne categoriche
for cat_col in cat_cols:
    # Fill dei NaN con il valore pi√π frequente della colonna
    full_data[cat_col].fillna(full_data[cat_col].value_counts().idxmax(), inplace=True)
    # Label encoding
    le = preprocessing.LabelEncoder()
    le.fit(full_data[cat_col])
    full_data[cat_col] = le.transform(full_data[cat_col])

# Suddivisione di nuovo in train e test dopo il preprocessing
train = full_data[:len(train)]
test = full_data[len(train):]

# Split train/validazione
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, random_state=42)

# Applicazione logaritmo ai target
y_train = np.log(y_train)
y_valid = np.log(y_valid)

# Conversione in DMatrix
dtrain = xgb.DMatrix(X_train, y_train)
dvalid = xgb.DMatrix(X_valid, y_valid)
dtest = xgb.DMatrix(test)

watchlist = [(dtrain, 'train'), (dvalid, 'eval')]

# Parametri modello
params = {
    "objective": "reg:linear",
    "booster": "gblinear",
    "eval_metric": "rmse",
    "subsample": 0.8,
    "colsample_bytree": 0.8,
    "silent": 1,
    "seed": 0
}

# Training
gbm = xgb.train(params, dtrain, 150, evals=watchlist, verbose_eval=1)

# Predict e inverso log
test_prediction = gbm.predict(dtest)
test_prediction = np.exp(test_prediction)

# Costruzione DataFrame soluzione
test_solution = pd.DataFrame({'Id': test['Id'], 'SalePrice': test_prediction})
print(test_solution)

test_solution.to_csv("test_solution.csv", index=False)